{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d213c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import random\n",
    "import glob\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "\n",
    "# ML & utilities (kept at top for convenience)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()  # interactive mode\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8013a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 736 total image files\n"
     ]
    }
   ],
   "source": [
    "def load_pickle_image(file_path):\n",
    "    with open(file_path, \"rb\") as f:         \n",
    "        return pickle.load(f)                 \n",
    "\n",
    "# Get all .pck file paths (don't load all images at once - too memory intensive!)\n",
    "file_paths = []                              \n",
    "for vol in range(1, 9):                      \n",
    "    folder = f\"archive/vol{vol:02d}\"         \n",
    "    file_paths += sorted(glob.glob(f\"{folder}/*.pck\"))  \n",
    "\n",
    "print(f\"Found {len(file_paths)} total image files\")\n",
    "# Load images individually as needed, not all at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36ba8897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution (numeric): Counter({0: 547, 1: 144, 2: 45})\n",
      "Label distribution (names): Counter({'Normal': 547, 'Torn': 144, 'Partially torn': 45})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('archive/vol01/329637-8.pck', 0, 'Normal'),\n",
       " ('archive/vol01/390116-9.pck', 0, 'Normal'),\n",
       " ('archive/vol01/404663-8.pck', 1, 'Torn'),\n",
       " ('archive/vol01/406320-9.pck', 0, 'Normal'),\n",
       " ('archive/vol01/412857-8.pck', 0, 'Normal'),\n",
       " ('archive/vol01/412865-8.pck', 1, 'Torn'),\n",
       " ('archive/vol01/415102-9.pck', 0, 'Normal'),\n",
       " ('archive/vol01/425707-8.pck', 0, 'Normal'),\n",
       " ('archive/vol01/425713-8.pck', 0, 'Normal'),\n",
       " ('archive/vol01/437474-8.pck', 0, 'Normal')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Associate labels from metadata.csv to image file paths\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Read metadata\n",
    "meta = pd.read_csv(\"metadata.csv\")\n",
    "# Map filename -> numeric label\n",
    "fn_to_label = dict(zip(meta['volumeFilename'], meta['aclDiagnosis']))\n",
    "label_names = {0: 'Normal', 1: 'Torn', 2: 'Partially torn'}\n",
    "\n",
    "# Build mapping list (file_path, numeric_label, label_name_or_None)\n",
    "mapped = []\n",
    "for p in file_paths:\n",
    "    fname = os.path.basename(p)\n",
    "    label = fn_to_label.get(fname, None)\n",
    "    mapped.append((p, label, label_names.get(label) if label is not None else None))\n",
    "\n",
    "\n",
    "# Summary\n",
    "print(\"Label distribution (numeric):\", Counter(l for _p, l, _n in mapped if l is not None))\n",
    "print(\"Label distribution (names):\", Counter(n for _p, l, n in mapped if n is not None))\n",
    "\n",
    "# Show 10 examples\n",
    "mapped[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa2981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 298 sampled items (seed=42)\n",
      "\n",
      "SVM acc: 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83        45\n",
      "           1       0.33      0.42      0.37        12\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.70        60\n",
      "   macro avg       0.39      0.41      0.40        60\n",
      "weighted avg       0.70      0.70      0.70        60\n",
      "\n",
      "\n",
      "LogReg acc: 0.7166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87        45\n",
      "           1       0.33      0.25      0.29        12\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.72        60\n",
      "   macro avg       0.39      0.38      0.39        60\n",
      "weighted avg       0.70      0.72      0.71        60\n",
      "\n",
      "\n",
      "SVM acc: 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83        45\n",
      "           1       0.33      0.42      0.37        12\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.70        60\n",
      "   macro avg       0.39      0.41      0.40        60\n",
      "weighted avg       0.70      0.70      0.70        60\n",
      "\n",
      "\n",
      "LogReg acc: 0.7166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87        45\n",
      "           1       0.33      0.25      0.29        12\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.72        60\n",
      "   macro avg       0.39      0.38      0.39        60\n",
      "weighted avg       0.70      0.72      0.71        60\n",
      "\n",
      "\n",
      "Training small CNN (3 epochs)...\n",
      "Epoch 1/3\n",
      "\n",
      "Training small CNN (3 epochs)...\n",
      "Epoch 1/3\n",
      "15/15 - 1s - 48ms/step - accuracy: 0.7017 - loss: 0.8815 - val_accuracy: 0.7500 - val_loss: 0.7142\n",
      "Epoch 2/3\n",
      "15/15 - 1s - 48ms/step - accuracy: 0.7017 - loss: 0.8815 - val_accuracy: 0.7500 - val_loss: 0.7142\n",
      "Epoch 2/3\n",
      "15/15 - 0s - 5ms/step - accuracy: 0.7437 - loss: 0.7207 - val_accuracy: 0.7500 - val_loss: 0.6917\n",
      "Epoch 3/3\n",
      "15/15 - 0s - 5ms/step - accuracy: 0.7437 - loss: 0.7207 - val_accuracy: 0.7500 - val_loss: 0.6917\n",
      "Epoch 3/3\n",
      "15/15 - 0s - 5ms/step - accuracy: 0.7437 - loss: 0.7175 - val_accuracy: 0.7500 - val_loss: 0.7089\n",
      "15/15 - 0s - 5ms/step - accuracy: 0.7437 - loss: 0.7175 - val_accuracy: 0.7500 - val_loss: 0.7089\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "MAX_SAMPLES = 300\n",
    "IMG_SIZE = (64, 64)\n",
    "hog_params = dict(orientations=9, pixels_per_cell=(8,8), cells_per_block=(2,2))\n",
    "\n",
    "# Build per-label lists then sample without loading files yet\n",
    "by_label = {}\n",
    "for p, label, _n in mapped:\n",
    "    by_label.setdefault(label, []).append(p)\n",
    "\n",
    "sampled = []\n",
    "total = len(mapped)\n",
    "for label, paths in by_label.items():\n",
    "    k = max(1, int(len(paths) / total * MAX_SAMPLES))\n",
    "    k = min(k, len(paths))\n",
    "    sampled += [(p, label) for p in random.sample(paths, k)]\n",
    "if len(sampled) > MAX_SAMPLES:\n",
    "    sampled = random.sample(sampled, MAX_SAMPLES)\n",
    "\n",
    "print(f'Using {len(sampled)} sampled items (seed=42)')\n",
    "\n",
    "# Now load only sampled files and extract HOG features\n",
    "X = []\n",
    "y = []\n",
    "for p, label in sampled:\n",
    "    img = load_pickle_image(p)\n",
    "    arr = np.asarray(img)\n",
    "    sl = arr[arr.shape[0] // 2] if arr.ndim == 3 else arr\n",
    "    if sl.ndim == 3:\n",
    "        sl = rgb2gray(sl)\n",
    "    sl_resized = resize(sl, IMG_SIZE, anti_aliasing=True)\n",
    "    fd = hog((sl_resized * 255).astype(np.uint8), orientations=hog_params['orientations'], pixels_per_cell=hog_params['pixels_per_cell'], cells_per_block=hog_params['cells_per_block'], visualize=False, feature_vector=True)\n",
    "    X.append(fd)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.vstack(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# SVM\n",
    "svm = SVC(kernel='rbf', class_weight='balanced', random_state=42)\n",
    "svm.fit(X_tr, y_tr)\n",
    "y_svm = svm.predict(X_te)\n",
    "print('\\nSVM acc:', accuracy_score(y_te, y_svm))\n",
    "print(classification_report(y_te, y_svm))\n",
    "\n",
    "# Logistic Regression\n",
    "logr = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "logr.fit(X_tr, y_tr)\n",
    "y_log = logr.predict(X_te)\n",
    "print('\\nLogReg acc:', accuracy_score(y_te, y_log))\n",
    "print(classification_report(y_te, y_log))\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Build small image dataset from sampled files\n",
    "X_img = []\n",
    "y_img = []\n",
    "for p, label in sampled:\n",
    "    img = load_pickle_image(p)\n",
    "    arr = np.asarray(img)\n",
    "    sl = arr[arr.shape[0] // 2] if arr.ndim == 3 else arr\n",
    "    if sl.ndim == 3:\n",
    "        sl = rgb2gray(sl)\n",
    "    sl_resized = resize(sl, IMG_SIZE, anti_aliasing=True)\n",
    "    X_img.append(np.expand_dims(sl_resized.astype(np.float32), -1))\n",
    "    y_img.append(label)\n",
    "X_img = np.stack(X_img)\n",
    "y_img = np.array(y_img)\n",
    "\n",
    "Xtr_img, Xte_img, ytr_img, yte_img = train_test_split(X_img, y_img, test_size=0.2, stratify=y_img, random_state=42)\n",
    "\n",
    "n_classes = len(np.unique(y_img))\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=Xtr_img.shape[1:]),\n",
    "    layers.Conv2D(16, 3, activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.MaxPool2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax'),\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "print('\\nTraining small CNN (3 epochs)...')\n",
    "model.fit(Xtr_img, ytr_img, epochs=3, batch_size=16, validation_data=(Xte_img, yte_img), verbose=2)\n",
    "loss, acc = model.evaluate(Xte_img, yte_img, verbose=0)\n",
    "print('\\nCNN test acc:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
